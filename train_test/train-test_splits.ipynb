{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sets de train y test\n",
    "\n",
    "El aprendizaje supervisado busca **aprender a partir de datos conocidos** (etapa de desarrollo) para **hacer predicciones sobre datos nuevos** (sistema en prod). Queremos:\n",
    "\n",
    "1. Un modelo \"bueno\" (que hagan buenas predicciones)\n",
    "2. Una **estimación confiable** de la performance del modelo\n",
    "\n",
    "Si entrenamos un modelo con todos nuestros datos y luego evaluamos el modelo usando esos mismos datos, no podríamos **saber qué tan bien puede funcionar nuestro modelo con datos que nunca vio**.\n",
    "\n",
    "La **partición en train y test** nos permite **evaluar si un modelo aprende patrones que generalizan** a nuevos datos. Si un modelo hace buenas predicciones sobre una observación dada, queremos que sea porque aprendió las características relevantes del proceso generador de datos, y no porque ya haya visto esa observación en particular.\n",
    "\n",
    "En otras palabras, la partición train-test permite tener una **estimación confiable de la performance de los modelos**.\n",
    "\n",
    "Es fundamental **_ocultar_ los datos de test** incluso de nosotros mismos. No se pueden utilizar para mejorar el modelo; solo se pueden usar para evaluar el modelo al final de todo el proceso. A la hora de **tomar decisiones de desarrollo** (selección de metodología, ajuste de hiperparámetros, selección de features, etc.) **no podemos usar el set de test**. \n",
    "\n",
    "Si hiciéramos esto, las nuevas versiones del modelo que vamos creando estarían indirectamente moldeadas por haber visto los datos de test. Así como un modelo corre el riesgo de sobreajustarse a los datos de entrenamiento, nosotros corremos el **riesgo de sobreajustar los modelos a los datos de test** por medio de la exploración de alternativas. La estimación de la performance en test sería optimista, y por ende, poco confiable.\n",
    "\n",
    "Esto no significa que _siempre_ necesitemos un conjunto de test independiente; pero generalmente es así. \n",
    "\n",
    "Resumiendo:\n",
    "\n",
    "![train_test](img/train_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando desarrollamos modelos:\n",
    "\n",
    "       datos           -->  métrica(datos) optimista [overfitting / modelos optimizan métrica de train]\n",
    "|-------------------|\n",
    "  Train   |  Val.      -->  métrica(val.) optimista  [meta-overfitting / NOSOTROS optimizamos métrica(val)] \n",
    "|-------------------|\n",
    "  Train | Val. |Test   -->  métrica(test) confiable \n",
    "|--------------|----|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de _split_\n",
    "\n",
    "Una propiedad clave de los sets de train y test es que deben ser **representativos de los datos a los que se enfrentará el modelo** en el futuro. Si bien no siempre es posible lograr esto (¡el futuro es desconocido por definición!), podemos tomar decisiones para **simular el escenario de uso** y evitar errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos datos al azar para un escenario de clasificación multi-clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.uniform(0, 1, size=(n, 5))\n",
    "y = np.random.choice([\"A\",\"B\",\"C\"], size=n, p=[.1, .5, .4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified split\n",
    "\n",
    "En general es importante que todas las clases relevantes de un set de datos estén representadas en train y en test (generalmente las clases relevantes son las del _target_ pero podría tratarse de un feature categórico). \n",
    "\n",
    "En un dataset lo suficientemente grande, un _random split_ conservará en promedio todas las clases con sus respectivas frecuencias relativas. Pero en **datasets pequeños y/o desbalanceados**, es probable que una partición completamente aleatoria reduzca sensiblemente o elimine por completo alguna clase de alguno de los sets; la _partición estratificada_ permite que se conserven todas las clases con seguridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    0.495\n",
       "B    0.405\n",
       "A    0.100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C    0.495\n",
      "B    0.405\n",
      "A    0.100\n",
      "dtype: float64\n",
      "C    0.50625\n",
      "B    0.38750\n",
      "A    0.10625\n",
      "dtype: float64\n",
      "B    0.475\n",
      "C    0.450\n",
      "A    0.075\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pd.Series(y).value_counts(normalize=True),\n",
    "    pd.Series(y_train).value_counts(normalize=True),\n",
    "    pd.Series(y_test).value_counts(normalize=True),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C    0.495\n",
      "B    0.405\n",
      "A    0.100\n",
      "dtype: float64\n",
      "C    0.49375\n",
      "B    0.40625\n",
      "A    0.10000\n",
      "dtype: float64\n",
      "C    0.5\n",
      "B    0.4\n",
      "A    0.1\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pd.Series(y).value_counts(normalize=True),\n",
    "    pd.Series(y_train).value_counts(normalize=True),\n",
    "    pd.Series(y_test).value_counts(normalize=True),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-wise split\n",
    "\n",
    "Cuando los datos están indexados en distintos momentos del tiempo, es importante hacer una partición según el tiempo. Las **observaciones de test debén ser siempre posteriores al set de train**. \n",
    "\n",
    "Si la partición fuera aleatoria, nuestro modelo podría ver los datos tanto antes como después de las fechas que está tratando de predecir -- entonces no sería representativo del caso de uso más típico: cuando usamos datos históricos para predecir el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo = np.random.randint(2000, 2011, size=n) # 10 periodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_test_frac = 0.2\n",
    "# min_test_size = 50 # alternativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo_freq_cumulative = pd.Series(tiempo).value_counts(\n",
    "    normalize=True).sort_index(ascending=False).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010    0.090\n",
       "2009    0.170\n",
       "2008    0.265\n",
       "2007    0.355\n",
       "2006    0.435\n",
       "2005    0.545\n",
       "2004    0.610\n",
       "2003    0.705\n",
       "2002    0.800\n",
       "2001    0.905\n",
       "2000    1.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiempo_freq_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primer periodo que supera min_test_frac\n",
    "tiempo_start_test = (tiempo_freq_cumulative >= min_test_frac).idxmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = tiempo >= tiempo_start_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[~is_test]\n",
    "y_train = y[~is_test]\n",
    "X_test = X[is_test]\n",
    "y_test = y[is_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject-wise split\n",
    "\n",
    "Cuando contamos con **múltiples observaciones por sujeto**, la mayor parte de las veces nos interesa hacer predicciones sobre sujetos que están fuera de nuestros datos. En este caso, hay que ser muy cuidadosos en la partición de los datos. \n",
    "\n",
    "En particular, **no debe haber sujetos que estén en ambos sets**. \n",
    "\n",
    "Si hubiera sujetos de train en test, a un modelo podría resultarle fácil hacer buenas predicciones sobre test porque podría sobreajustarse a las particularidades de esos sujetos específicos en lugar de aprender los patrones relevantes para generalizar. Esto sucedería si hay **correlaciones espurias** entre los sujetos y el _target_ (es decir, correlaciones presentes en nuestra muestra que no son representativas del verdadero proceso generador).\n",
    "\n",
    "Al igual que en la _partición temporal_, es fundamental que el split train-test replique lo más fielmente posible el escenario de uso: el funcionamiento del modelo en producción. Solo de esta manera podemos tener una estimación confiable de la verdadera capacidad predictiva de nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.choice(list(\"abcdefghij\"), size=n) # 10 sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    26\n",
       "e    25\n",
       "a    22\n",
       "i    22\n",
       "f    20\n",
       "j    19\n",
       "g    18\n",
       "h    18\n",
       "d    15\n",
       "c    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ids).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=.2, random_state=42)\n",
    "for train_idx, test_idx in gss.split(X, y, ids):\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'c', 'd', 'e', 'f', 'g', 'h', 'j'], dtype='<U1')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ids[train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'i'], dtype='<U1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ids[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pensar:\n",
    "\n",
    "* ¿Cómo partimos los datos en cada uno de los siguientes escenarios? Y ya que estamos, ¿cuáles son los features?\n",
    "\n",
    ">1. Queremos predecir quién gana cada partido de la NBA. Tenemos los resultados de partidos de los últimos 10 años y estadísticas de cada uno.\n",
    ">2. Queremos predecir cuándo un conductor está usando el celular mientras maneja. Tenemos un dataset etiquetado de imágenes de muchos conductores usando/no usando el celular.\n",
    ">3. Queremos predecir si va a llover o no. Tenemos datos históricos diarios de lluvia y otros datos meteorológicos. \n",
    "\n",
    "* Por último, imaginemos que trabajamos en un hospital que decide tercerizar el desarrollo de un modelo de predicción de mortalidad de pacientes en una UTI a un consultor externo. El hospital nos provee un dataset con datos de pacientes que estuvieron en la UTI en los últimos 2 años. \n",
    "\n",
    ">¿Qué datos le compartimos al consultor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta 2:\n",
    "\n",
    "Random:\n",
    "train: tomas1 tomas3, fv2, fv5, --> modelo puede aprender correlacion espuria\n",
    "test:  tomas2 tomas10, fv1, fv4, --> metrica optimista (no confiable)\n",
    "\n",
    "Por sujeto:\n",
    "train: tomas1, tomas3, tomas2, tomas10 --> modelo puede aprender correlacion espuria\n",
    "test:  fv2, fv5, fv1, fv4, ...         --> metrica confiable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Recomendamos leer: \n",
    "\n",
    "* Howard y Gugger (2020) - Deep Learning for Coders with fastai and PyTorch (_Part 1, Chapter 1, Validation Sets and Test Sets_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "70aae090dcf60b41e7cc1692a84d4f6e0a269d03152970a28664643b73443561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
